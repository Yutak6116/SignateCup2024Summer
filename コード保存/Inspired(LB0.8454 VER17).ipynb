{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "127324d3-7aec-406c-883e-8fff0940e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import unicodedata\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import copy\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import clone_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 17\n",
    "    AUTHOR = 'Yuta.K'\n",
    "    COMPETITION = 'SC2024'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = [\n",
    "        # 'adaboost','lightgbm','xgboost',\n",
    "                   'catboost']\n",
    "    # seed 42\n",
    "    # seed 15 25 35 45 55\n",
    "    seed = 25\n",
    "    n_folds = 7\n",
    "    target_col = 'ProdTaken'\n",
    "    metric = 'AUC'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 300\n",
    "    early_stopping_round = 200\n",
    "    verbose = 100\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves' : 15,\n",
    "        'lambda_l1' : 0.2,\n",
    "        'lambda_l2' : 0.2,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'lambda':2,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        'learning_rate': 0.25,\n",
    "        # 'eval_metric': 'AUC',\n",
    "        'depth':1,\n",
    "        'l2_leaf_reg' : 6,\n",
    "        'iterations':1000,\n",
    "        'random_seed': seed,\n",
    "        'one_hot_max_size' : 20,\n",
    "    }\n",
    "    classification_adaboost_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 1.0,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    model_weight_dict = {\n",
    "        # 'adaboost': 0.06,'lightgbm': 0.2, 'xgboost': 0.04, \n",
    "                         'catboost': 1}\n",
    "    \n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# AUC\n",
    "\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('dataset/train_processed.csv', index_col=0)\n",
    "test_df = pd.read_csv('dataset/test_processed.csv', index_col=0)\n",
    "test0 = pd.read_csv('dataset/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "a300dc9d-c16f-415b-ad09-af339f7a86f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'TypeofContact', 'CityTier', 'DurationOfPitch', 'Occupation',\n",
       "       'Gender', 'NumberOfPersonVisiting', 'NumberOfFollowups',\n",
       "       'ProductPitched', 'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
       "       'PitchSatisfactionScore', 'Designation', 'MonthlyIncome', 'Married',\n",
       "       'CarPossesion', 'NumberOfOffspring', 'Single', 'family_members',\n",
       "       'Income / child', 'MoneyforOneTrip', 'AllOfcontact',\n",
       "       'NumberOfPersonVisiting - NumberOfOffspring', 'ProdTaken'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b86b5-073d-4c8b-bffc-19117399879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_features ['Age', 'DurationOfPitch', 'MonthlyIncome', 'NumberOfPersonVisiting', 'NumberOfFollowups', 'NumberOfTrips', 'NumberOfOffspring', 'family_members', 'Income / child', 'MoneyforOneTrip', 'AllOfcontact', 'NumberOfPersonVisiting - NumberOfOffspring']\n",
      "categorical_features ['TypeofContact', 'CityTier', 'Occupation', 'Gender', 'ProductPitched', 'PreferredPropertyStar', 'Passport', 'PitchSatisfactionScore', 'Designation', 'Married', 'CarPossesion', 'Single', 'ProdTaken']\n",
      "features for training:['Age', 'TypeofContact', 'CityTier', 'DurationOfPitch', 'Occupation', 'Gender', 'NumberOfFollowups', 'ProductPitched', 'PreferredPropertyStar', 'NumberOfTrips', 'Passport', 'PitchSatisfactionScore', 'Designation', 'MonthlyIncome', 'CarPossesion', 'NumberOfOffspring', 'Single', 'Income / child', 'MoneyforOneTrip', 'AllOfcontact', 'NumberOfPersonVisiting - NumberOfOffspring']\n"
     ]
    }
   ],
   "source": [
    "#学習に必要となるリストの作成\n",
    "default_categorical_features = ['TypeofContact', 'CityTier', 'Occupation', 'Gender', 'ProductPitched', 'PreferredPropertyStar', 'Passport', 'PitchSatisfactionScore', 'Designation', 'Married', 'CarPossesion']\n",
    "default_numerical_features = ['Age', 'DurationOfPitch', 'MonthlyIncome', \n",
    "                            'NumberOfPersonVisiting', 'NumberOfFollowups', 'NumberOfTrips', 'NumberOfOffspring'\n",
    "                              ]\n",
    "added_numerical_features = [\n",
    "    'family_members',\n",
    "    # 'MonthlyIncome / Age', \n",
    "    # 'MonthlyIncome / family_members',\n",
    "    # 'NumberOfPersonVisiting * NumberOfTrips',\n",
    "    # 'Age / NumberOfTrips',\n",
    "    # 'PreferredPropertyStar / MonthlyIncome', \n",
    "    'Income / child',\n",
    "    'MoneyforOneTrip',\n",
    "    'AllOfcontact',\n",
    "    'NumberOfPersonVisiting - NumberOfOffspring',\n",
    "    # '|NumberOfFollowups - NumberOfTrips|'\n",
    "]\n",
    "numerical_features = default_numerical_features + added_numerical_features\n",
    "\n",
    "#特徴量の指定\n",
    "features = train_df.columns.tolist()\n",
    "#カテゴリカル特徴量の指定\n",
    "categorical_features = copy.deepcopy(features)\n",
    "print(f'numerical_features {numerical_features}')\n",
    "for i in numerical_features:\n",
    "    categorical_features.remove(i)\n",
    "print(f'categorical_features {categorical_features}')\n",
    "\n",
    "#学習に使用しない特徴量は以下で除外\n",
    "RemoveList=[CFG.target_col, 'NumberOfPersonVisiting', 'Married', 'family_members']\n",
    "for i in RemoveList:\n",
    "    if i in numerical_features:\n",
    "        numerical_features.remove(i)\n",
    "        features.remove(i)\n",
    "    elif i in categorical_features:\n",
    "        categorical_features.remove(i)\n",
    "        features.remove(i)\n",
    "    else:\n",
    "        features.remove(i)\n",
    "print(f'features for training:{features}')\n",
    "\n",
    "for col in categorical_features:\n",
    "    train_df[col] = train_df[col].astype(int)\n",
    "    test_df[col] = test_df[col].astype(int)\n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric = 'auc')\n",
    "model.fit(train_df[features],train_df[CFG.target_col])\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(train_df[features])\n",
    "shap.plots.waterfall(shap_values[0])\n",
    "\n",
    "shap.plots.bar(shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fbeff-a646-49d3-bae8-1c22d5b6919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RFEのためにインポート\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# num_select = 100\n",
    "# train_x = train_df.drop([CFG.target_col],axis=1)\n",
    "# train_y = train_df[CFG.target_col]\n",
    "# rfe = RFE(estimator=GradientBoostingRegressor(random_state=0), n_features_to_select=num_select, step=0.5)\n",
    "# rfe.fit(train_x, train_y.to_numpy().ravel())\n",
    "# Train_x = pd.DataFrame(rfe.transform(train_x), columns=train_x.columns[rfe.support_])\n",
    "\n",
    "# rfe_column_list = Train_x.columns.tolist()\n",
    "# categorical_features = list(set(categorical_features) & set(rfe_column_list))\n",
    "# numerical_features = list(set(numerical_features) & set(rfe_column_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d6f98-1031-4757-8e6c-41f5b4b5b280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Learning & Predicting\n",
    "\n",
    "#1段階目の学習\n",
    "def Pre_Learning(train_df,test_df, features, categorical_features):\n",
    "    \n",
    "    #adaboostでの学習メソッドの定義\n",
    "    def adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        model = AdaBoostClassifier(**CFG.classification_adaboost_params)\n",
    "        model.fit(x_train, y_train)\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "        return model, valid_pred\n",
    "\n",
    "    #lightgbmでの学習メソッドの定義\n",
    "    def lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "        lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "        model = lgb.train(\n",
    "                    params = CFG.classification_lgb_params,\n",
    "                    train_set = lgb_train,\n",
    "                    num_boost_round = CFG.num_boost_round,\n",
    "                    valid_sets = [lgb_train, lgb_valid],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                                  verbose=CFG.verbose)]\n",
    "                )\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict(x_valid)\n",
    "        return model, valid_pred\n",
    "\n",
    "    #xgboostでの学習メソッドの定義\n",
    "    def xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "        model = xgb.train(\n",
    "                    CFG.classification_xgb_params,\n",
    "                    dtrain = xgb_train,\n",
    "                    num_boost_round = CFG.num_boost_round,\n",
    "                    evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                    early_stopping_rounds = CFG.early_stopping_round,\n",
    "                    verbose_eval = CFG.verbose,\n",
    "                    maximize = CFG.metric_maximize_flag,\n",
    "                )\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "        return model, valid_pred\n",
    "\n",
    "    #catboostでの学習メソッドの定義\n",
    "    def catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "        cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "        model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "        model.fit(cat_train,\n",
    "                  eval_set = [cat_valid],\n",
    "                  early_stopping_rounds = CFG.early_stopping_round,\n",
    "                  verbose = CFG.verbose,\n",
    "                  use_best_model = True)\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "        return model, valid_pred\n",
    "\n",
    "\n",
    "\n",
    "    #任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "    def gradient_boosting_model_cv_training(method, train_df, features, categorical_features):\n",
    "        # Create a numpy array to store out of folds predictions\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        oof_fold = np.zeros(len(train_df))\n",
    "        kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "        for fold, (train_index, valid_index) in enumerate(kfold.split(train_df[features],train_df[CFG.target_col])):\n",
    "            print('-'*50)\n",
    "            print(f'{method} training fold {fold+1}')\n",
    "\n",
    "            x_train = train_df[features].iloc[train_index]\n",
    "            y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "            x_valid = train_df[features].iloc[valid_index]\n",
    "            y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "\n",
    "            model = None  # モデル変数を初期化する\n",
    "            valid_pred = None\n",
    "\n",
    "            if method == 'adaboost':\n",
    "                model, valid_pred = adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            if method == 'lightgbm':\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            if method == 'xgboost':\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            if method == 'catboost':\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)  \n",
    "            # Save best model\n",
    "            pickle.dump(model, open(f'model/{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[valid_index] = valid_pred\n",
    "            oof_fold[valid_index] = fold + 1\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "\n",
    "        # Compute out of folds metric\n",
    "        #score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "        score = roc_auc_score(train_df[CFG.target_col], oof_predictions)\n",
    "        print(f'{method} our out of folds CV AUC is {score}')\n",
    "        # Create a dataframe to store out of folds predictions\n",
    "        oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "        oof_df.to_csv(f'oof/oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "\n",
    "    #adaboostの学習済みモデル読み込み関数\n",
    "    def adaboost_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'model/adaboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict_proba(x_test)[:, 1]\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #lightgbmの学習モデル読み込み関数\n",
    "    def lightgbm_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'model/lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict(x_test)\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #xgboostの学習モデル読み込み関数\n",
    "    def xgboost_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'model/xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict(xgb.DMatrix(x_test))\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #catboostの学習モデル読み込み関数\n",
    "    def catboost_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'model/catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict_proba(x_test)[:, 1]\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #任意のメソッドに対して予測を返す関数\n",
    "    def gradient_boosting_model_inference(method, test_df, features, categorical_features):\n",
    "        x_test = test_df[features]\n",
    "        if method == 'adaboost':\n",
    "            test_pred = adaboost_inference(x_test)\n",
    "        if method == 'lightgbm':\n",
    "            test_pred = lightgbm_inference(x_test)\n",
    "        if method == 'xgboost':\n",
    "            test_pred = xgboost_inference(x_test)\n",
    "        if method == 'catboost':\n",
    "            test_pred = catboost_inference(x_test)\n",
    "        return test_pred\n",
    "\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        gradient_boosting_model_cv_training(method, train_df, features, categorical_features)\n",
    "        test_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, test_df, features, categorical_features)\n",
    "        \n",
    "        \n",
    "\n",
    "Pre_Learning(train_df,test_df, features, categorical_features)\n",
    "\n",
    "test_df['target'] = 0\n",
    "for method in CFG.METHOD_LIST:\n",
    "    test_df['target'] += test_df[f'{method}_pred_prob']*CFG.model_weight_dict[method]\n",
    "\n",
    "test_ensemble[f'target{CFG.seed}'] = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c9e56-dabb-4593-9430-2086039f860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8431642663467436\n",
    "\n",
    "0.8436632495507805\n",
    "\n",
    "0.8442378872163461\n",
    "\n",
    "0.8433085141867247\n",
    "\n",
    "0.8440711111589323\n",
    "\n",
    "0.8448686773044685 depth 1\n",
    "\n",
    "0.8463323389535071 depth 2\n",
    "\n",
    "0.8464866740550254 depth 3\n",
    "\n",
    "0.8448915417639526 depyh 1 iteration 500\n",
    "\n",
    "0.8448888518275428 age以外丸め\n",
    "\n",
    "0.8448915417639526 ageも丸め\n",
    "\n",
    "0.8428478625765287 MonthlyIncome 10000割\n",
    "\n",
    "0.8453646343300444 MonthlyIncome 1000割\n",
    "\n",
    "0.841955139930492 dummyしない、categorical\n",
    "\n",
    "0.8434241814523507 dummyしない、numerical      0.8439537626830501 NumberOfPersonVisiting削除   0.8455892440202712 さらにDurationOfPitch * NumberOfPersonVisiting削除\n",
    "\n",
    "\n",
    "0.8460280398971369 productとDesignationを逆順に (missに気付いた)\n",
    "\n",
    "# 0.8460791486889251 Occupationを逆順に\n",
    "\n",
    "# 0.8461864099032698 CityTierを逆順に\n",
    "\n",
    "# 0.847051560701105 PreferredPropertyStarとPitchSatisfactionScoreを逆順に\n",
    "\n",
    "0.8462940073596661 ↑までのやつをちゃんとやったやつ\n",
    "\n",
    "0.8470330673882869 rate 0.25\n",
    "\n",
    "\n",
    "0.8423058403899333\n",
    "\n",
    "0.8451292648941778 offspring member 差\n",
    "\n",
    "0.8454527297474687 trip fallowup差の絶対値\n",
    "\n",
    "\n",
    "\n",
    "seed\n",
    "15                   25                   35                   45                   55                   ave\n",
    "0.8453162154746662   0.8439736009640733   0.8405385521686267   0.8455287204510485   0.8459184249884333   0.8442551028093697\n",
    "特徴量デフォ\n",
    "# 0.8462640818171058   0.8411347093254716   0.8381424913115053   0.8433064967344172   0.8451326273146902\n",
    "# Single追加\n",
    "0.845181718654171    0.8437799255425602   0.8406629617275848   0.8458363819279312   0.8463407450047882   0.8443603465714071\n",
    "Single追加、Married削除\n",
    "# 0.8450314184572676   0.8414988594669622   0.8405126615306814   0.8453874987895286   0.8452287925413443\n",
    "# family_members追加 不採用\n",
    "# 0.8441706388060985   0.8412863544905798   0.8403341170014741   0.8457435791217895   0.845655147462314\n",
    "# MonthlyIncome / Age追加 不採用\n",
    "# 0.8444645143588805   0.8430798695918829   0.8398539633523063   0.843268165140576   0.8448639699157512\n",
    "# MonthlyIncome / family_members追加　不採用\n",
    "# 0.8431649388308462   0.8433650028513326   0.8399464299163968   0.8451171601803334   0.8451003480777715\n",
    "# NumberOfPersonVisiting * NumberOfTrips追加　不採用\n",
    "# 0.8447402328408956   0.8425707991263087   0.8406838087347615   0.8452045831136552   0.8460108915525237\n",
    "# NumberOfPersonVisiting - NumberOfOffspring追加　不採用\n",
    "0.845406328344398    0.8420408816535578   0.8415022218874745   0.8449261746952301   0.8472657468877436   0.8442282706936808\n",
    "NumberOfPersonVisiting - NumberOfOffspring, AllOfContact追加 審議\n",
    "0.8466265507483403   0.8439053438276719   0.8404588628024834   0.8440398406481671   0.846983639806755    0.8444028475666835\n",
    "Income / child追加　審議\n",
    "0.8457321468920473   0.8429494076760026   0.8429440278031828   0.8453619443936344   0.8464005960899085   0.8446776245709552\n",
    "MoneyforOneTrip追加　審議\n",
    "# Age / NumberOfTrips不採用\n",
    "# PreferredPropertyStar / MonthlyIncome 不採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc0766-ac57-48d1-bf72-d6b8a55bee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([0.8457321468920473 ,  0.8429494076760026  , 0.8429440278031828  , 0.8453619443936344   ,0.8464005960899085])\n",
    "\n",
    "# test_ensemble = {}\n",
    "# test_ensemble = pd.DataFrame(test_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88dfb93-c061-47bb-a799-8f4822f55bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc757a1e-9515-439a-b5fa-64d47a0538c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble['target'] = test_ensemble[['target15', 'target25', 'target35', 'target45', 'target55']].mean(axis=1)\n",
    "0.092092　0.232057\t\n",
    "\n",
    "0.094424 0.227196 0.255615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75273715-fa4d-4d55-a99d-fd6e31fbd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c14997-e33c-41a8-b41d-c7cc68494142",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c6a37-2b41-4c82-b6ba-04d572e3fc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35218f-6f8b-4c4b-b173-aca3309b381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [i+3489 for i in range(3489)]\n",
    "submission = pd.DataFrame({'ID':id_list, 'ProdTaken':test_ensemble['target']})\n",
    "submission.to_csv(f'prediction/seed15-25-35-45-55_ver17_{CFG.AUTHOR}_submission.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c611985-0be5-45c6-81b1-6981cf4d64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(f'model/catboost_fold1_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "feature_importances = model.get_feature_importance()\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature':train_df[features].columns,\n",
    "    'Importance': feature_importances}).sort_values(by = 'Importance',ascending=False)\n",
    "print(feature_importances_df)\n",
    "\n",
    "non_zero_feature_importances_df = feature_importances_df[feature_importances_df['Importance']==0.0]\n",
    "non_zero_feature_importances_df_list = non_zero_feature_importances_df['Feature'].tolist()\n",
    "print(len(non_zero_feature_importances_df_list),non_zero_feature_importances_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff90702-3b6c-48e0-96f6-0468907c9b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a050b5-fa9a-43b8-9a34-e1831c7a6ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
