{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad41c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Age  TypeofContact  CityTier  DurationOfPitch  Occupation  Gender  \\\n",
      "0     50.000000            1.0       2.0             15.0         0.0     0.0   \n",
      "1     56.000000            0.0       1.0             14.0         1.0     0.0   \n",
      "2     36.290526            1.0       1.0             10.0         0.0     1.0   \n",
      "3     37.000000            1.0       2.0             18.0         2.0     1.0   \n",
      "4     48.000000            0.0       3.0             17.0         2.0     1.0   \n",
      "...         ...            ...       ...              ...         ...     ...   \n",
      "3484  40.000000            1.0       2.0             26.0         1.0     0.0   \n",
      "3485  43.000000            1.0       1.0              9.0         0.0     0.0   \n",
      "3486  31.000000            1.0       1.0             14.0         2.0     1.0   \n",
      "3487  56.000000            0.0       2.0             15.0         1.0     0.0   \n",
      "3488  42.000000            1.0       1.0              9.0         2.0     0.0   \n",
      "\n",
      "      NumberOfPersonVisiting  NumberOfFollowups  ProductPitched  \\\n",
      "0                        1.0                4.0             0.0   \n",
      "1                        1.0                4.0             3.0   \n",
      "2                        1.0                3.0             0.0   \n",
      "3                        1.0                3.0             3.0   \n",
      "4                        1.0                3.0             0.0   \n",
      "...                      ...                ...             ...   \n",
      "3484                     2.0                3.0             0.0   \n",
      "3485                     3.0                3.0             0.0   \n",
      "3486                     3.0                2.0             3.0   \n",
      "3487                     3.0                6.0             2.0   \n",
      "3488                     3.0                1.0             0.0   \n",
      "\n",
      "      PreferredPropertyStar  NumberOfTrips  Passport  PitchSatisfactionScore  \\\n",
      "0                       3.0            5.0       1.0                     4.0   \n",
      "1                       3.0            2.0       1.0                     4.0   \n",
      "2                       3.0            4.0       0.0                     4.0   \n",
      "3                       4.0            1.0       0.0                     5.0   \n",
      "4                       4.0            4.0       0.0                     4.0   \n",
      "...                     ...            ...       ...                     ...   \n",
      "3484                    3.0            3.0       0.0                     1.0   \n",
      "3485                    5.0            5.0       0.0                     3.0   \n",
      "3486                    3.0            5.0       0.0                     4.0   \n",
      "3487                    3.0            7.0       1.0                     4.0   \n",
      "3488                    3.0            3.0       0.0                     1.0   \n",
      "\n",
      "      Designation  MonthlyIncome  married  car_possesion  offspring  \\\n",
      "0             1.0       253905.0      3.0            0.0        0.0   \n",
      "1             3.0       404475.0      0.0            1.0        0.0   \n",
      "2             1.0       278145.0      1.0            0.0        0.0   \n",
      "3             3.0       326805.0      0.0            1.0        0.0   \n",
      "4             1.0       258435.0      2.0            1.0        0.0   \n",
      "...           ...            ...      ...            ...        ...   \n",
      "3484          1.0       258900.0      0.0            1.0        0.0   \n",
      "3485          1.0       260415.0      1.0            1.0        2.0   \n",
      "3486          3.0       317340.0      2.0            1.0        1.0   \n",
      "3487          4.0       527910.0      1.0            0.0        2.0   \n",
      "3488          1.0       278190.0      1.0            0.0        1.0   \n",
      "\n",
      "      ProdTaken  AdultMembers  Age_CityTier Designation_ProductPitched  \n",
      "0             1           1.0     25.000000                    1.0_0.0  \n",
      "1             0           1.0     56.000000                    3.0_3.0  \n",
      "2             1           1.0     36.290526                    1.0_0.0  \n",
      "3             0           1.0     18.500000                    3.0_3.0  \n",
      "4             1           1.0     16.000000                    1.0_0.0  \n",
      "...         ...           ...           ...                        ...  \n",
      "3484          1           2.0     20.000000                    1.0_0.0  \n",
      "3485          0           1.0     43.000000                    1.0_0.0  \n",
      "3486          0           2.0     31.000000                    3.0_3.0  \n",
      "3487          1           1.0     28.000000                    4.0_2.0  \n",
      "3488          0           2.0     42.000000                    1.0_0.0  \n",
      "\n",
      "[3489 rows x 22 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3489 entries, 0 to 3488\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         3489 non-null   float64\n",
      " 1   TypeofContact               3489 non-null   float64\n",
      " 2   CityTier                    3489 non-null   float64\n",
      " 3   DurationOfPitch             3489 non-null   float64\n",
      " 4   Occupation                  3489 non-null   float64\n",
      " 5   Gender                      3489 non-null   float64\n",
      " 6   NumberOfPersonVisiting      3489 non-null   float64\n",
      " 7   NumberOfFollowups           3489 non-null   float64\n",
      " 8   ProductPitched              3489 non-null   float64\n",
      " 9   PreferredPropertyStar       3489 non-null   float64\n",
      " 10  NumberOfTrips               3489 non-null   float64\n",
      " 11  Passport                    3489 non-null   float64\n",
      " 12  PitchSatisfactionScore      3489 non-null   float64\n",
      " 13  Designation                 3489 non-null   float64\n",
      " 14  MonthlyIncome               3489 non-null   float64\n",
      " 15  married                     3489 non-null   float64\n",
      " 16  car_possesion               3489 non-null   float64\n",
      " 17  offspring                   3489 non-null   float64\n",
      " 18  ProdTaken                   3489 non-null   int64  \n",
      " 19  AdultMembers                3489 non-null   float64\n",
      " 20  Age_CityTier                3489 non-null   float64\n",
      " 21  Designation_ProductPitched  3489 non-null   object \n",
      "dtypes: float64(20), int64(1), object(1)\n",
      "memory usage: 599.8+ KB\n",
      "features for training:['Age', 'TypeofContact', 'CityTier', 'DurationOfPitch', 'Gender', 'NumberOfPersonVisiting', 'NumberOfFollowups', 'PreferredPropertyStar', 'NumberOfTrips', 'Passport', 'PitchSatisfactionScore', 'MonthlyIncome', 'married', 'car_possesion', 'offspring', 'AdultMembers', 'Age_CityTier', 'Designation_ProductPitched']\n",
      "['Age', 'DurationOfPitch', 'NumberOfPersonVisiting', 'NumberOfFollowups', 'NumberOfTrips', 'MonthlyIncome', 'offspring', 'family_members', 'ChildRate', 'MoneyforOneTrip', 'AllOfcontact', 'Income_child', 'Income_person', 'Income_Age', 'AdultMembers', 'Age_CityTier', 'New', 'AdultRate', 'PreferredPropertyStar_NumberOfFollowups', 'PreferredPropertyStar_NumberOfFollowups']\n",
      "['TypeofContact', 'CityTier', 'Gender', 'PreferredPropertyStar', 'Passport', 'PitchSatisfactionScore', 'married', 'car_possesion', 'Designation_ProductPitched']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3489 entries, 0 to 3488\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         3489 non-null   float64\n",
      " 1   TypeofContact               3489 non-null   int64  \n",
      " 2   CityTier                    3489 non-null   int32  \n",
      " 3   DurationOfPitch             3489 non-null   float64\n",
      " 4   Occupation                  3489 non-null   float64\n",
      " 5   Gender                      3489 non-null   int64  \n",
      " 6   NumberOfPersonVisiting      3489 non-null   float64\n",
      " 7   NumberOfFollowups           3489 non-null   float64\n",
      " 8   ProductPitched              3489 non-null   float64\n",
      " 9   PreferredPropertyStar       3489 non-null   int32  \n",
      " 10  NumberOfTrips               3489 non-null   float64\n",
      " 11  Passport                    3489 non-null   int64  \n",
      " 12  PitchSatisfactionScore      3489 non-null   int64  \n",
      " 13  Designation                 3489 non-null   float64\n",
      " 14  MonthlyIncome               3489 non-null   float64\n",
      " 15  married                     3489 non-null   int32  \n",
      " 16  car_possesion               3489 non-null   int64  \n",
      " 17  offspring                   3489 non-null   float64\n",
      " 18  AdultMembers                3489 non-null   float64\n",
      " 19  Age_CityTier                3489 non-null   float64\n",
      " 20  Designation_ProductPitched  3489 non-null   object \n",
      " 21  ProdTaken                   3489 non-null   int64  \n",
      "dtypes: float64(12), int32(3), int64(6), object(1)\n",
      "memory usage: 558.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3489 entries, 3489 to 6977\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         3489 non-null   float64\n",
      " 1   TypeofContact               3489 non-null   int64  \n",
      " 2   CityTier                    3489 non-null   int32  \n",
      " 3   DurationOfPitch             3489 non-null   float64\n",
      " 4   Occupation                  3489 non-null   float64\n",
      " 5   Gender                      3489 non-null   int64  \n",
      " 6   NumberOfPersonVisiting      3489 non-null   float64\n",
      " 7   NumberOfFollowups           3489 non-null   float64\n",
      " 8   ProductPitched              3489 non-null   float64\n",
      " 9   PreferredPropertyStar       3489 non-null   int32  \n",
      " 10  NumberOfTrips               3489 non-null   float64\n",
      " 11  Passport                    3489 non-null   int64  \n",
      " 12  PitchSatisfactionScore      3489 non-null   int64  \n",
      " 13  Designation                 3489 non-null   float64\n",
      " 14  MonthlyIncome               3489 non-null   float64\n",
      " 15  married                     3489 non-null   int32  \n",
      " 16  car_possesion               3489 non-null   int64  \n",
      " 17  offspring                   3489 non-null   float64\n",
      " 18  AdultMembers                3489 non-null   float64\n",
      " 19  Age_CityTier                3489 non-null   float64\n",
      " 20  Designation_ProductPitched  3489 non-null   object \n",
      "dtypes: float64(12), int32(3), int64(5), object(1)\n",
      "memory usage: 558.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import unicodedata\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import copy\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import clone_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 16\n",
    "    AUTHOR = 'Naoki'\n",
    "    COMPETITION = 'SC2024'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = ['catboost']\n",
    "    seed = 51\n",
    "    n_folds = 3\n",
    "    target_col = 'ProdTaken'\n",
    "    metric = 'AUC'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 300\n",
    "    early_stopping_round = 200\n",
    "    verbose = 0\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.10,\n",
    "        'lambda_l1' : 10,\n",
    "        'lambda_l2' : 100,\n",
    "        'max_depth':2,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'learning_rate': 0.20,\n",
    "        'lambda':1000,\n",
    "        'alpha':1,\n",
    "        'max_depth':2,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        #'learning_rate': 0.10,\n",
    "        'depth':1,\n",
    "        #'l2_leaf_reg' : 6,\n",
    "        'iterations':1000,\n",
    "        'random_seed': seed,\n",
    "        'one_hot_max_size':40,\n",
    "        \n",
    "    }\n",
    "    classification_adaboost_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.5,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    classification_randomforest_params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': 'auto',\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model_weight_dict = {'catboost': 1.00}\n",
    "    \n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# AUC\n",
    "\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('data/train_processed.csv', index_col=0)\n",
    "test_df = pd.read_csv('data/test_processed.csv', index_col=0)\n",
    "\n",
    "#学習に必要となるリストの作成\n",
    "LabelList = ['TypeofContact','car_possesion','Passport','Gender','PitchSatisfactionScore']\n",
    "#OneHotList = ['CityTier','Occupation','ProductPitched','PreferredPropertyStar','Designation','married']\n",
    "OneHotList = []\n",
    "default_categorical_features = ['TypeofContact','car_possesion','Passport','Gender','PitchSatisfactionScore',\n",
    "                                'CityTier','Occupation','ProductPitched','PreferredPropertyStar','Designation','married']\n",
    "default_numerical_features = ['Age','DurationOfPitch','NumberOfPersonVisiting','NumberOfFollowups','NumberOfTrips',\n",
    "                              'MonthlyIncome','offspring']\n",
    "NumericalList = ['Age','DurationOfPitch','NumberOfPersonVisiting','NumberOfFollowups','NumberOfTrips','MonthlyIncome','offspring',\n",
    "                 'family_members','ChildRate', 'MoneyforOneTrip','AllOfcontact','Income_child','Income_person','Income_Age',\n",
    "                 'AdultMembers','Age_CityTier','New','AdultRate','PreferredPropertyStar_NumberOfFollowups',\n",
    "                'PreferredPropertyStar_NumberOfFollowups']\n",
    "\n",
    "MissList = ['Age','TypeofContact','DurationOfPitch','NumberOfFollowups','NumberOfTrips','MonthlyIncome']\n",
    "\n",
    "def Preprocessing(train_df, test_df):\n",
    "    \n",
    "    def miss_dealing(train_df,test_df):\n",
    "        #ラベルエンコーディング\n",
    "        LabelList = ['TypeofContact','Occupation','ProductPitched','Designation','married']\n",
    "        for col in LabelList:\n",
    "            encoder = LabelEncoder()\n",
    "            combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "            encoder.fit(combined)\n",
    "            train_df[col] = encoder.transform(train_df[col])\n",
    "            test_df[col] = encoder.transform(test_df[col])\n",
    "        features = ['Age','TypeofContact','CityTier','DurationOfPitch','Occupation','Gender','NumberOfPersonVisiting','NumberOfFollowups',\n",
    "                    'ProductPitched','PreferredPropertyStar','NumberOfTrips','Passport','PitchSatisfactionScore','Designation',\n",
    "                    'MonthlyIncome','married','car_possesion','offspring']\n",
    "        train_x = train_df[features]\n",
    "        imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "        imputer.fit(train_x)\n",
    "        train_x_imputed = imputer.transform(train_x)\n",
    "        train_df_imputed = pd.DataFrame(train_x_imputed, columns=train_x.columns)\n",
    "        train_df_imputed[CFG.target_col] = train_df[CFG.target_col]\n",
    "        test_df_imputed = imputer.transform(test_df)\n",
    "        test_df_imputed = pd.DataFrame(test_df_imputed, columns=test_df.columns)\n",
    "        original_index = list(range(3489,6978))\n",
    "        test_df_imputed.index = original_index\n",
    "        return train_df_imputed,test_df_imputed\n",
    "    \n",
    "    #特徴量作成\n",
    "    def make_features(input_df):\n",
    "        df = input_df.copy()\n",
    "        def count_adult_members(input_str):\n",
    "            if input_str == 1.0:\n",
    "                return 2\n",
    "            else:\n",
    "                return 1\n",
    "        #df['MonthlyIncome'] = df['MonthlyIncome']//1000\n",
    "        ProductPitched_Dict = {0.0:1,3.0:2,1.0:3,4.0:4,2.0:5}\n",
    "        #df['ProductPitched'] = df['ProductPitched'].map(ProductPitched_Dict)\n",
    "        #df['family_members'] = df['married'].apply(count_adult_members) + df['offspring']\n",
    "        #df['AdultRate'] = 1-df['offspring']/df['NumberOfPersonVisiting']\n",
    "        df['AdultMembers'] = df['NumberOfPersonVisiting']-df['offspring']\n",
    "        #df['ChildRate'] = df['offspring']/df['NumberOfPersonVisiting']\n",
    "        #df['family_ChildRate'] = df['offspring']/df['family_members']\n",
    "        #df['Income_person'] = df['MonthlyIncome']/df['family_members']\n",
    "        #df['Income_child'] =  df['MonthlyIncome']/(df['offspring']+0.0001)\n",
    "        #df['MoneyforOneTrip'] = df['MonthlyIncome']/df['NumberOfTrips']\n",
    "        #df['Income_Age'] = df['MonthlyIncome'] / df['Age']\n",
    "        df['Age_CityTier'] = df['Age'] / df['CityTier']\n",
    "        #df['PreferredPropertyStar_NumberOfFollowups'] = df['PreferredPropertyStar']/df['NumberOfFollowups']\n",
    "        #df['New'] = df['PreferredPropertyStar']/df['CityTier']\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #組み合わせ特徴量\n",
    "        pair_combination_list = []\n",
    "        combination_list = []\n",
    "        pair_combination_list = [('Designation','ProductPitched')]\n",
    "        #combination_list = [('Gender','CityTier','married')]\n",
    "        for a,b in pair_combination_list:\n",
    "            df[f'{a}_{b}'] = df[a].astype(str) + '_' + df[b].astype(str)\n",
    "        for a,b,c in combination_list:\n",
    "            df[f'{a}_{b}_{c}'] = df[a].astype(str) + '_' + df[b].astype(str) + '_' + df[c].astype(str)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        return df\n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    def encoding(train_df,test_df):\n",
    "        #ラベルエンコーディング\n",
    "        for col in LabelList:\n",
    "            encoder = LabelEncoder()\n",
    "            combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "            encoder.fit(combined)\n",
    "            train_df[col] = encoder.transform(train_df[col])\n",
    "            test_df[col] = encoder.transform(test_df[col])\n",
    "        #ワンホットエンコーディング\n",
    "        train_df2 = train_df.drop([CFG.target_col],axis=1)\n",
    "        ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "        train_df2 = ohe.fit_transform(train_df2)\n",
    "        test_df = ohe.transform(test_df)\n",
    "        train_df = pd.concat([train_df2,train_df[CFG.target_col]],axis=1)\n",
    "        return train_df, test_df\n",
    "    train_df, test_df = miss_dealing(train_df, test_df)\n",
    "    train_df = make_features(train_df)\n",
    "    test_df = make_features(test_df)\n",
    "    print(train_df)\n",
    "    train_df.info()\n",
    "    train_df, test_df = encoding(train_df, test_df)\n",
    "    return train_df, test_df\n",
    "    \n",
    "#前処理の実行\n",
    "train_df, test_df = Preprocessing(train_df,test_df)\n",
    "\n",
    "\n",
    "\n",
    "#特徴量の指定\n",
    "features = train_df.columns.tolist()\n",
    "#学習に使用しない特徴量は以下で除外\n",
    "RemoveList=[CFG.target_col,'Occupation','ProductPitched','Designation']\n",
    "for i in RemoveList:\n",
    "    features.remove(i)\n",
    "print(f'features for training:{features}')\n",
    "#features = ['Age','TypeofContact','CityTier','DurationOfPitch','Occupation','Gender','NumberOfPersonVisiting','NumberOfFollowups',\n",
    "                    #'ProductPitched','PreferredPropertyStar','NumberOfTrips','Passport','PitchSatisfactionScore','Designation',\n",
    "                    #'MonthlyIncome','married','car_possesion','offspring']\n",
    "\n",
    "#カテゴリカル特徴量の指定\n",
    "categorical_features = copy.deepcopy(features)\n",
    "print(NumericalList)\n",
    "for i in NumericalList:\n",
    "    if i in categorical_features:\n",
    "        categorical_features.remove(i)\n",
    "print(categorical_features)\n",
    "\n",
    "for col in categorical_features:\n",
    "    if train_df[col].dtype == 'float64':\n",
    "        train_df[col] = train_df[col].astype(int)\n",
    "        test_df[col] = test_df[col].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "train_df.info()\n",
    "test_df.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa67f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8239418017940314\n",
      "catboost our out of folds CV PR-AUC is 0.4914410910260205\n",
      "Fold 1 test CV is 0.8492553100100939\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.817804467828187\n",
      "catboost our out of folds CV PR-AUC is 0.4752171757937069\n",
      "Fold 2 test CV is 0.8519156841268818\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.855400692168363\n",
      "catboost our out of folds CV PR-AUC is 0.5376527316183148\n",
      "Fold 3 test CV is 0.8287548590082254\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8498698141279972\n",
      "catboost our out of folds CV PR-AUC is 0.5142597292186217\n",
      "Fold 4 test CV is 0.8296259905933896\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8054691543039503\n",
      "catboost our out of folds CV PR-AUC is 0.4694157654217251\n",
      "Fold 5 test CV is 0.8438647638683074\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8270482038123167\n",
      "catboost our out of folds CV PR-AUC is 0.4953387702637383\n",
      "Fold 6 test CV is 0.8580391083048773\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8427109388476799\n",
      "catboost our out of folds CV PR-AUC is 0.5438059013018414\n",
      "Fold 7 test CV is 0.8373198677061185\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8364482706572367\n",
      "catboost our out of folds CV PR-AUC is 0.5220019132597171\n",
      "Fold 8 test CV is 0.8463855421686748\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8263015891840607\n",
      "catboost our out of folds CV PR-AUC is 0.5106692733097179\n",
      "Fold 9 test CV is 0.8390057556428925\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "catboost our out of folds CV AUC is 0.8342569432465069\n",
      "catboost our out of folds CV PR-AUC is 0.489498844532128\n",
      "Fold 10 test CV is 0.8365655133904604\n",
      "0.8420732394819922\n"
     ]
    }
   ],
   "source": [
    "testCVlist = []\n",
    "for Fold in range(0,10):\n",
    "        #外側のループ trainとtestを分割する\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train_df[features],\n",
    "        train_df[CFG.target_col],\n",
    "        test_size=0.5,\n",
    "        stratify=train_df[CFG.target_col],\n",
    "        random_state=Fold\n",
    "    )\n",
    "\n",
    "    # 訓練データセットの作成\n",
    "    train_df_fortrain = X_train\n",
    "    train_df_fortrain[CFG.target_col] = y_train\n",
    "\n",
    "    # テストデータセットの作成\n",
    "    train_df_fortest = X_test.copy()  # 元のテストデータセットのコピーを作成\n",
    "    \n",
    "    # テストデータのターゲット列\n",
    "    train_df_fortest_target = y_test\n",
    "\n",
    "\n",
    "    #Learning & Predicting\n",
    "\n",
    "    #1段階目の学習\n",
    "    def Pre_Learning(train_df,test_df, features, categorical_features):\n",
    "\n",
    "        def randomforest_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "            # モデルのパラメータは適切に設定する\n",
    "            model = RandomForestClassifier(**CFG.classification_randomforest_params)\n",
    "            model.fit(x_train, y_train)\n",
    "            # バリデーションデータに対する予測確率を計算\n",
    "            valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "            return model, valid_pred\n",
    "\n",
    "        #adaboostでの学習メソッドの定義\n",
    "        def adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "            model = AdaBoostClassifier(**CFG.classification_adaboost_params)\n",
    "            model.fit(x_train, y_train)\n",
    "            # Predict validation\n",
    "            valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "            return model, valid_pred\n",
    "\n",
    "        #lightgbmでの学習メソッドの定義\n",
    "        def lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "            lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "            lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "            model = lgb.train(\n",
    "                        params = CFG.classification_lgb_params,\n",
    "                        train_set = lgb_train,\n",
    "                        num_boost_round = CFG.num_boost_round,\n",
    "                        valid_sets = [lgb_train, lgb_valid],\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                                      verbose=CFG.verbose)]\n",
    "                    )\n",
    "            # Predict validation\n",
    "            valid_pred = model.predict(x_valid)\n",
    "            return model, valid_pred\n",
    "\n",
    "        #xgboostでの学習メソッドの定義\n",
    "        def xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "            xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "            xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "            model = xgb.train(\n",
    "                        CFG.classification_xgb_params,\n",
    "                        dtrain = xgb_train,\n",
    "                        num_boost_round = CFG.num_boost_round,\n",
    "                        evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                        early_stopping_rounds = CFG.early_stopping_round,\n",
    "                        verbose_eval = CFG.verbose,\n",
    "                        maximize = CFG.metric_maximize_flag,\n",
    "                    )\n",
    "            # Predict validation\n",
    "            valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "            return model, valid_pred\n",
    "\n",
    "        #catboostでの学習メソッドの定義\n",
    "        def catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "            cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "            cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "            model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "            model.fit(cat_train,\n",
    "                      eval_set = [cat_valid],\n",
    "                      early_stopping_rounds = CFG.early_stopping_round,\n",
    "                      verbose = CFG.verbose,\n",
    "                      use_best_model = True)\n",
    "            # Predict validation\n",
    "            valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "            return model, valid_pred\n",
    "\n",
    "\n",
    "\n",
    "        #任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "        def gradient_boosting_model_cv_training(method, train_df, features, categorical_features):\n",
    "            # Create a numpy array to store out of folds predictions\n",
    "            oof_predictions = np.zeros(len(train_df))\n",
    "            oof_fold = np.zeros(len(train_df))\n",
    "            kfold = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "            for fold, (train_index, valid_index) in enumerate(kfold.split(train_df[features],train_df[CFG.target_col])):\n",
    "                print('-'*50)\n",
    "                print(f'{method} training fold {fold+1}')\n",
    "\n",
    "                x_train = train_df[features].iloc[train_index]\n",
    "                y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "                x_valid = train_df[features].iloc[valid_index]\n",
    "                y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "\n",
    "                model = None  # モデル変数を初期化する\n",
    "                valid_pred = None\n",
    "\n",
    "                if method == 'randomforest':\n",
    "                    model, valid_pred = randomforest_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "                if method == 'adaboost':\n",
    "                    model, valid_pred = adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "                if method == 'lightgbm':\n",
    "                    model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "                if method == 'xgboost':\n",
    "                    model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "                if method == 'catboost':\n",
    "                    model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)  \n",
    "                # Save best model\n",
    "                pickle.dump(model, open(f'model/{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "                # Add to out of folds array\n",
    "                oof_predictions[valid_index] = valid_pred\n",
    "                oof_fold[valid_index] = fold + 1\n",
    "                del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "                gc.collect()\n",
    "\n",
    "            # Compute out of folds metric\n",
    "            score = roc_auc_score(train_df[CFG.target_col], oof_predictions)\n",
    "            precision, recall, thresholds = precision_recall_curve(train_df[CFG.target_col], oof_predictions)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            print(f'{method} our out of folds CV AUC is {score}')\n",
    "            print(f'{method} our out of folds CV PR-AUC is {pr_auc}')\n",
    "            # Create a dataframe to store out of folds predictions\n",
    "            oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "            oof_df.to_csv(f'oof/oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "\n",
    "        #randomforestの学習済みモデル読み込み関数\n",
    "        def randomforest_inference(x_test):\n",
    "            test_pred = np.zeros(len(x_test))\n",
    "            for fold in range(CFG.n_folds):\n",
    "                model = pickle.load(open(f'model/randomforest_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "                pred = model.predict_proba(x_test)[:, 1]\n",
    "                test_pred += pred\n",
    "            return test_pred / CFG.n_folds\n",
    "\n",
    "        #adaboostの学習済みモデル読み込み関数\n",
    "        def adaboost_inference(x_test):\n",
    "            test_pred = np.zeros(len(x_test))\n",
    "            for fold in range(CFG.n_folds):\n",
    "                model = pickle.load(open(f'model/adaboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "                # Predict\n",
    "                pred = model.predict_proba(x_test)[:, 1]\n",
    "                test_pred += pred\n",
    "            return test_pred / CFG.n_folds\n",
    "\n",
    "        #lightgbmの学習モデル読み込み関数\n",
    "        def lightgbm_inference(x_test):\n",
    "            test_pred = np.zeros(len(x_test))\n",
    "            for fold in range(CFG.n_folds):\n",
    "                model = pickle.load(open(f'model/lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "                # Predict\n",
    "                pred = model.predict(x_test)\n",
    "                test_pred += pred\n",
    "            return test_pred / CFG.n_folds\n",
    "\n",
    "        #xgboostの学習モデル読み込み関数\n",
    "        def xgboost_inference(x_test):\n",
    "            test_pred = np.zeros(len(x_test))\n",
    "            for fold in range(CFG.n_folds):\n",
    "                model = pickle.load(open(f'model/xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "                # Predict\n",
    "                pred = model.predict(xgb.DMatrix(x_test))\n",
    "                test_pred += pred\n",
    "            return test_pred / CFG.n_folds\n",
    "\n",
    "        #catboostの学習モデル読み込み関数\n",
    "        def catboost_inference(x_test):\n",
    "            test_pred = np.zeros(len(x_test))\n",
    "            for fold in range(CFG.n_folds):\n",
    "                model = pickle.load(open(f'model/catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "                # Predict\n",
    "                pred = model.predict_proba(x_test)[:, 1]\n",
    "                test_pred += pred\n",
    "            return test_pred / CFG.n_folds\n",
    "\n",
    "        #任意のメソッドに対して予測を返す関数\n",
    "        def gradient_boosting_model_inference(method, test_df, features, categorical_features):\n",
    "            x_test = test_df[features]\n",
    "            if method == 'randomforest':\n",
    "                test_pred = randomforest_inference(x_test)\n",
    "            if method == 'adaboost':\n",
    "                test_pred = adaboost_inference(x_test)\n",
    "            if method == 'lightgbm':\n",
    "                test_pred = lightgbm_inference(x_test)\n",
    "            if method == 'xgboost':\n",
    "                test_pred = xgboost_inference(x_test)\n",
    "            if method == 'catboost':\n",
    "                test_pred = catboost_inference(x_test)\n",
    "            return test_pred\n",
    "\n",
    "        for method in CFG.METHOD_LIST:\n",
    "            gradient_boosting_model_cv_training(method, train_df, features, categorical_features)\n",
    "            test_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, test_df, features, categorical_features)\n",
    "\n",
    "\n",
    "\n",
    "    Pre_Learning(train_df_fortrain,train_df_fortest, features, categorical_features)\n",
    "\n",
    "    train_df_fortest['target'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        train_df_fortest['target'] += train_df_fortest[f'{method}_pred_prob']*CFG.model_weight_dict[method]\n",
    "\n",
    "    roc_auc = roc_auc_score(train_df_fortest_target, train_df_fortest['target'])\n",
    "    testCVlist.append(roc_auc)\n",
    "    print(f'Fold {Fold + 1} test CV is {roc_auc}')\n",
    "    \n",
    "print(sum(testCVlist)/len(testCVlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b454a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d476751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV:0.8535376698694843 model_weight_dict:{'catboost': 1.0}\n"
     ]
    }
   ],
   "source": [
    "train_df['pred_prob'] = 0\n",
    "for method in CFG.METHOD_LIST:\n",
    "    oof_df = pd.read_csv(f'oof/oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "    train_df['pred_prob'] += CFG.model_weight_dict[method] * oof_df[f'{method}_prediction']\n",
    "score = roc_auc_score(train_df[CFG.target_col], train_df[f'pred_prob'])\n",
    "print(f' CV:{score} model_weight_dict:{CFG.model_weight_dict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644952e",
   "metadata": {},
   "source": [
    "cvから0.0015ぐらいは下がる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d53d7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#提出ファイルの出力 \n",
    "test_df['target'] = 0 \n",
    "for method in CFG.METHOD_LIST: \n",
    "    test_df['target'] += test_df[f'{method}_pred_prob']*CFG.model_weight_dict[method]\n",
    "\n",
    "test_df['target'].to_csv(f'prediction/catboost_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_cv{score}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8fbf58",
   "metadata": {},
   "source": [
    "#提出ファイルの出力 \n",
    "test_df['target'] = 0 \n",
    "for method in CFG.METHOD_LIST: \n",
    "    test_df['target'] += test_df[f'{method}_pred_prob']*CFG.model_weight_dict[method]\n",
    "\n",
    "test_df['target'].to_csv(f'prediction/catboost_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf7222f",
   "metadata": {},
   "source": [
    "model = pickle.load(open(f'model/catboost_fold1_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "feature_importances = model.get_feature_importance()\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature':train_df[features].columns,\n",
    "    'Importance': feature_importances}).sort_values(by = 'Importance',ascending=False)\n",
    "print(feature_importances_df)\n",
    "\n",
    "non_zero_feature_importances_df = feature_importances_df[feature_importances_df['Importance']==0.0]\n",
    "non_zero_feature_importances_df_list = non_zero_feature_importances_df['Feature'].tolist()\n",
    "print(len(non_zero_feature_importances_df_list),non_zero_feature_importances_df_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
