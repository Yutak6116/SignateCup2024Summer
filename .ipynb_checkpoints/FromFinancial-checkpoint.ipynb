{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "B3WEPx1JJqlG"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import category_encoders as ce\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import clone_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 100\n",
    "    AUTHOR = 'Yuta.K'\n",
    "    COMPETITION = 'SignateCup2024Summer'\n",
    "    DATA_PATH = Path('/dataset')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = ['lightgbm', 'xgboost', 'catboost']\n",
    "#     METHOD_LIST = [ 'adaboost','lightgbm', 'xgboost', 'catboost']\n",
    "    seed = 42\n",
    "    n_folds = 2\n",
    "    target_col = 'ProdTaken'\n",
    "    metric = 'auc'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 500\n",
    "    early_stopping_round = 200\n",
    "    verbose = 25\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "    classification_cat_params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'iterations': num_boost_round,\n",
    "        'random_seed': seed,\n",
    "    }\n",
    "    classification_adaboost_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 1.0,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# f1_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro'), CFG.metric_maximize_flag\n",
    "\n",
    "# ====================================================\n",
    "# XGBoost Metric\n",
    "# ====================================================\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "g6R4KoxhL91E"
   },
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "El2B8eayMmyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features for training:['Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'RevLineCr_1.0', 'RevLineCr_0.0', 'RevLineCr_4.0', 'RevLineCr_3.0', 'RevLineCr_2.0', 'LowDoc_3.0', 'LowDoc_2.0', 'LowDoc_5.0', 'LowDoc_6.0', 'LowDoc_0.0', 'LowDoc_4.0', 'LowDoc_1.0', 'DisbursementDate', 'Sector', 'ApprovalDate', 'ApprovalFY', 'City', 'State', 'BankState', 'DisbursementGross', 'GrAppv', 'SBA_Appv', 'UrbanRural', 'DisbursementDay', 'DisbursementMonth', 'DisbursementYear', 'ApprovalDay', 'ApprovalMonth', 'CompanyLong', 'Bankraptcy_By_Year', 'State_Sector', 'City_State', 'ApprovalFY_Term', 'FranchiseCode_ApprovalDate', 'Term_NoEmp', 'City_BankState', 'NoEmp_SBA_Appv']\n"
     ]
    }
   ],
   "source": [
    "def Preprocessing(train_df, test_df):\n",
    "    \n",
    "    #欠損値に対する前処理\n",
    "    def deal_missing(input_df):\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        return df\n",
    "\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df):\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    \n",
    "    #特徴量作成\n",
    "    def make_features(input_df):\n",
    "        df = input_df.copy()\n",
    "        df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "        #破産した米国企業の数を外部データとして入力\n",
    "        #Bankraptcydataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                        -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "        #年毎のデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]#年毎の外部データの名前はここに入れる\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = k[-26]*2\n",
    "\n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "\n",
    "        #組み合わせ特徴量\n",
    "        df['State_Sector'] = df['State'].astype(str) + '_' + df['Sector'].astype(str)\n",
    "        df['City_State'] = df['City'] + '_' + df['State']\n",
    "        df['ApprovalFY_Term'] = df['ApprovalFY'].astype(str) + '_' + df['Term'].astype(str)\n",
    "        df['FranchiseCode_ApprovalDate'] = df['FranchiseCode'].astype(str) + '_' + df['ApprovalDate'].astype(str)\n",
    "        df['Term_NoEmp'] = df['Term'].astype(str) + '_' + df['NoEmp'].astype(str)\n",
    "        df['City_BankState'] = df['City'].astype(str) + '_' + df['BankState'].astype(str)\n",
    "        df['NoEmp_SBA_Appv'] = df['NoEmp'].astype(str) + '_' + df['SBA_Appv'].astype(str)\n",
    "        return df\n",
    "    \n",
    "    def encoding(train_df, test_df):\n",
    "        #ラベルエンコーディング\n",
    "        categorical_features_for_label = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector',\n",
    "                                'ApprovalFY_Term','City_State','City','ApprovalDate','BankState','DisbursementDate','State_Sector',\n",
    "                                   'FranchiseCode_ApprovalDate','Term_NoEmp','City_BankState','NoEmp_SBA_Appv']\n",
    "        for col in categorical_features_for_label:\n",
    "            encoder = LabelEncoder()\n",
    "            combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "            encoder.fit(combined)\n",
    "            train_df[col] = encoder.transform(train_df[col])\n",
    "            test_df[col] = encoder.transform(test_df[col])\n",
    "        #ワンホットエンコーディング\n",
    "        OneHotList = ['RevLineCr', 'LowDoc']\n",
    "        train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "        ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "        train_df2 = ohe.fit_transform(train_df2)\n",
    "        test_df = ohe.transform(test_df)\n",
    "        train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "        return train_df, test_df\n",
    "\n",
    "    train_df = deal_missing(train_df)\n",
    "    test_df = deal_missing(test_df)\n",
    "    train_df = clean_money(train_df)\n",
    "    test_df = clean_money(test_df)\n",
    "    train_df = make_features(train_df)\n",
    "    test_df = make_features(test_df)\n",
    "    train_df, test_df = encoding(train_df, test_df)\n",
    "    \n",
    "    \n",
    "    return train_df,test_df\n",
    "    \n",
    "#前処理の実行\n",
    "train_df, test_df = Preprocessing(train_df,test_df)\n",
    "\n",
    "#カテゴリカル特徴量の指定\n",
    "categorical_features = ['State', 'Sector','RevLineCr_0.0', 'RevLineCr_1.0', 'RevLineCr_2.0', 'RevLineCr_3.0', 'RevLineCr_4.0',\n",
    "                        'LowDoc_3.0', 'LowDoc_2.0', 'LowDoc_5.0', 'LowDoc_6.0', 'LowDoc_0.0', 'LowDoc_4.0','LowDoc_1.0',\n",
    "                       'ApprovalFY_Term','City_State','City','ApprovalDate','BankState','State_Sector','UrbanRural',\n",
    "                        'FranchiseCode_ApprovalDate','Term_NoEmp','City_BankState','NoEmp_SBA_Appv']\n",
    "\n",
    "#特徴量の指定\n",
    "features = train_df.columns.tolist()\n",
    "#学習に使用しない特徴量は以下で除外\n",
    "RemoveList=['MIS_Status','ApprovalYear']\n",
    "for i in RemoveList:\n",
    "    features.remove(i)\n",
    "print(f'features for training:{features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "quaQcTgQOjyJ"
   },
   "outputs": [],
   "source": [
    "#Learning & Predicting\n",
    "\n",
    "#1段階目の学習\n",
    "def Pre_Learning(train_df,test_df, features, categorical_features):\n",
    "    \n",
    "    #adaboostでの学習メソッドの定義\n",
    "    def adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        model = AdaBoostClassifier(**CFG.classification_adaboost_params)\n",
    "        model.fit(x_train, y_train)\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "        return model, valid_pred\n",
    "\n",
    "    #lightgbmでの学習メソッドの定義\n",
    "    def lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "        lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "        model = lgb.train(\n",
    "                    params = CFG.classification_lgb_params,\n",
    "                    train_set = lgb_train,\n",
    "                    num_boost_round = CFG.num_boost_round,\n",
    "                    valid_sets = [lgb_train, lgb_valid],\n",
    "                    feval = lgb_metric,\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                                  verbose=CFG.verbose)]\n",
    "                )\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict(x_valid)\n",
    "        return model, valid_pred\n",
    "\n",
    "    #xgboostでの学習メソッドの定義\n",
    "    def xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "        xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "        model = xgb.train(\n",
    "                    CFG.classification_xgb_params,\n",
    "                    dtrain = xgb_train,\n",
    "                    num_boost_round = CFG.num_boost_round,\n",
    "                    evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                    early_stopping_rounds = CFG.early_stopping_round,\n",
    "                    verbose_eval = CFG.verbose,\n",
    "                    feval = xgb_metric,\n",
    "                    maximize = CFG.metric_maximize_flag,\n",
    "                )\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "        return model, valid_pred\n",
    "\n",
    "    #catboostでの学習メソッドの定義\n",
    "    def catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "        cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "        cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "        model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "        model.fit(cat_train,\n",
    "                  eval_set = [cat_valid],\n",
    "                  early_stopping_rounds = CFG.early_stopping_round,\n",
    "                  verbose = CFG.verbose,\n",
    "                  use_best_model = True)\n",
    "        # Predict validation\n",
    "        valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "        return model, valid_pred\n",
    "\n",
    "    #任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "    def gradient_boosting_model_cv_training(method, train_df, features, categorical_features):\n",
    "        # Create a numpy array to store out of folds predictions\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        oof_fold = np.zeros(len(train_df))\n",
    "        kfold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "        for fold, (train_index, valid_index) in enumerate(kfold.split(train_df)):\n",
    "            print('-'*50)\n",
    "            print(f'{method} training fold {fold+1}')\n",
    "\n",
    "            x_train = train_df[features].iloc[train_index]\n",
    "            y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "            x_valid = train_df[features].iloc[valid_index]\n",
    "            y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "\n",
    "            model = None  # モデル変数を初期化する\n",
    "            valid_pred = None\n",
    "\n",
    "            if method == 'adaboost':\n",
    "                model, valid_pred = adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            if method == 'lightgbm':\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            if method == 'xgboost':\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            if method == 'catboost':\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)  \n",
    "            # Save best model\n",
    "            pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "            # Add to out of folds array\n",
    "            oof_predictions[valid_index] = valid_pred\n",
    "            oof_fold[valid_index] = fold + 1\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "\n",
    "        # Compute out of folds metric\n",
    "        score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "        print(f'{method} our out of folds CV f1score is {score}')\n",
    "        # Create a dataframe to store out of folds predictions\n",
    "        oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "        oof_df.to_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "\n",
    "    #adaboostの学習済みモデル読み込み関数\n",
    "    def adaboost_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'adaboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict_proba(x_test)[:, 1]\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #lightgbmの学習モデル読み込み関数\n",
    "    def lightgbm_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict(x_test)\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #xgboostの学習モデル読み込み関数\n",
    "    def xgboost_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict(xgb.DMatrix(x_test))\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #catboostの学習モデル読み込み関数\n",
    "    def catboost_inference(x_test):\n",
    "        test_pred = np.zeros(len(x_test))\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(f'catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            # Predict\n",
    "            pred = model.predict_proba(x_test)[:, 1]\n",
    "            test_pred += pred\n",
    "        return test_pred / CFG.n_folds\n",
    "\n",
    "    #任意のメソッドに対して予測を返す関数\n",
    "    def gradient_boosting_model_inference(method, test_df, features, categorical_features):\n",
    "        x_test = test_df[features]\n",
    "        if method == 'adaboost':\n",
    "            test_pred = adaboost_inference(x_test)\n",
    "        if method == 'lightgbm':\n",
    "            test_pred = lightgbm_inference(x_test)\n",
    "        if method == 'xgboost':\n",
    "            test_pred = xgboost_inference(x_test)\n",
    "        if method == 'catboost':\n",
    "            test_pred = catboost_inference(x_test)\n",
    "        return test_pred\n",
    "\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        gradient_boosting_model_cv_training(method, train_df, features, categorical_features)\n",
    "        test_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, test_df, features, categorical_features)\n",
    "        \n",
    "        \n",
    "#2段階目の学習　ニューラルネットワークによるスタッキング\n",
    "def Post_Learning(train_df,test_df):\n",
    "    #ニューラルネットワークモデル作成関数\n",
    "    def create_nn_model(input_shape):\n",
    "        model = Sequential([\n",
    "            Dense(64, input_shape=(input_shape,)),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "\n",
    "            Dense(32),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Dropout(0.5),\n",
    "\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    #ニューラルネットワーク用学習スケジューラー\n",
    "    def scheduler(epoch, lr):\n",
    "            if epoch < 10:\n",
    "                return lr\n",
    "            else:\n",
    "                return lr * np.exp(-0.1)\n",
    "\n",
    "    #特徴量同士で積を作る関数\n",
    "    def create_interaction_features(features):\n",
    "            n_features = features.shape[1]\n",
    "            interaction_features = []\n",
    "            for i in range(n_features):\n",
    "                for j in range(i + 1, n_features):\n",
    "                    interaction_features.append(features[:, i] * features[:, j])  \n",
    "            return np.column_stack(interaction_features)\n",
    "    \n",
    "    # OOF予測を基に新たな特徴量を作成\n",
    "    oof_features = np.zeros((train_df.shape[0], len(CFG.METHOD_LIST)))\n",
    "    for i, method in enumerate(CFG.METHOD_LIST):\n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "        oof_features[:, i] = oof_df[f'{method}_prediction']\n",
    "    \n",
    "    # テストデータの予測を基に特徴量を作成\n",
    "    test_features = np.zeros((test_df.shape[0], len(CFG.METHOD_LIST)))\n",
    "    for i, method in enumerate(CFG.METHOD_LIST):\n",
    "        test_features[:, i] = test_df[f'{method}_pred_prob']\n",
    "\n",
    "    # 特徴量同士の積を追加\n",
    "    oof_interaction_features = create_interaction_features(oof_features)\n",
    "    test_interaction_features = create_interaction_features(test_features)\n",
    "\n",
    "    # 元の特徴量と相互作用特徴量を組み合わせ\n",
    "    oof_combined_features = np.hstack([oof_features, oof_interaction_features])\n",
    "    test_combined_features = np.hstack([test_features, test_interaction_features])\n",
    "\n",
    "    # 特徴量の標準化\n",
    "    global oof_combined_features_scaled, test_combined_features_scaled\n",
    "    scaler = StandardScaler()\n",
    "    oof_combined_features_scaled = scaler.fit_transform(oof_combined_features)\n",
    "    test_combined_features_scaled = scaler.transform(test_combined_features)   \n",
    "    \n",
    "    # ニューラルネットワークモデルを学習\n",
    "    nn_model = create_nn_model(oof_combined_features_scaled.shape[1])\n",
    "    callbacks_list = [LearningRateScheduler(scheduler)]\n",
    "    nn_model.fit(oof_combined_features_scaled, train_df[CFG.target_col],\n",
    "                 validation_split=0.2, epochs=50, batch_size=32, callbacks=callbacks_list, verbose=1)\n",
    "    nn_model.save(f'nn_stacking_model_seed{CFG.seed}_ver{CFG.VER}.h5')\n",
    "    \n",
    "    #ロジスティック回帰モデルを学習\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(oof_combined_features_scaled, train_df[CFG.target_col])\n",
    "    pickle.dump(lr_model, open(f'lr_stacking_model_seed{CFG.seed}_ver{CFG.VER}.pkl','wb'))\n",
    "\n",
    "def Learning_and_Predicting(train_df, test_df, features, categorical_features):\n",
    "    Pre_Learning(train_df, test_df, features, categorical_features)\n",
    "    Post_Learning(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWzQv798OiQ-",
    "outputId": "57cabf2c-5c42-4084-e263-e00eaeb695ec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 18850, number of negative: 2303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13822\n",
      "[LightGBM] [Info] Number of data points in the train set: 21153, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891127 -> initscore=2.102300\n",
      "[LightGBM] [Info] Start training from score 2.102300\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's auc: 0.897924\ttraining's f1score: 0.584616\tvalid_1's auc: 0.753874\tvalid_1's f1score: 0.544304\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 18917, number of negative: 2237\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13986\n",
      "[LightGBM] [Info] Number of data points in the train set: 21154, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894252 -> initscore=2.134925\n",
      "[LightGBM] [Info] Start training from score 2.134925\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.882418\ttraining's f1score: 0.494358\tvalid_1's auc: 0.766754\tvalid_1's f1score: 0.492252\n",
      "lightgbm our out of folds CV f1score is 0.5188994558145035\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1\n",
      "[0]\ttrain-logloss:0.65982\ttrain-f1score:0.09818\teval-logloss:0.66014\teval-f1score:0.09563\n",
      "[25]\ttrain-logloss:0.33291\ttrain-f1score:0.67701\teval-logloss:0.34018\teval-f1score:0.65175\n",
      "[50]\ttrain-logloss:0.27178\ttrain-f1score:0.67807\teval-logloss:0.29038\teval-f1score:0.64808\n",
      "[75]\ttrain-logloss:0.24903\ttrain-f1score:0.68752\teval-logloss:0.28228\teval-f1score:0.64836\n",
      "[100]\ttrain-logloss:0.23553\ttrain-f1score:0.69878\teval-logloss:0.28106\teval-f1score:0.65009\n",
      "[125]\ttrain-logloss:0.22544\ttrain-f1score:0.71141\teval-logloss:0.28070\teval-f1score:0.65343\n",
      "[150]\ttrain-logloss:0.21787\ttrain-f1score:0.72472\teval-logloss:0.28084\teval-f1score:0.65484\n",
      "[175]\ttrain-logloss:0.21118\ttrain-f1score:0.73258\teval-logloss:0.28122\teval-f1score:0.65636\n",
      "[200]\ttrain-logloss:0.20460\ttrain-f1score:0.74316\teval-logloss:0.28169\teval-f1score:0.65741\n",
      "[212]\ttrain-logloss:0.20190\ttrain-f1score:0.74901\teval-logloss:0.28189\teval-f1score:0.65631\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2\n",
      "[0]\ttrain-logloss:0.65967\ttrain-f1score:0.09563\teval-logloss:0.66016\teval-f1score:0.09818\n",
      "[25]\ttrain-logloss:0.33102\ttrain-f1score:0.65903\teval-logloss:0.34111\teval-f1score:0.65107\n",
      "[50]\ttrain-logloss:0.27069\ttrain-f1score:0.66417\teval-logloss:0.29197\teval-f1score:0.64849\n",
      "[75]\ttrain-logloss:0.24799\ttrain-f1score:0.67199\teval-logloss:0.28361\teval-f1score:0.65296\n",
      "[100]\ttrain-logloss:0.23563\ttrain-f1score:0.68586\teval-logloss:0.28200\teval-f1score:0.65558\n",
      "[125]\ttrain-logloss:0.22915\ttrain-f1score:0.69579\teval-logloss:0.28190\teval-f1score:0.65946\n",
      "[150]\ttrain-logloss:0.22199\ttrain-f1score:0.70614\teval-logloss:0.28214\teval-f1score:0.65888\n",
      "[175]\ttrain-logloss:0.21581\ttrain-f1score:0.71553\teval-logloss:0.28243\teval-f1score:0.65991\n",
      "[200]\ttrain-logloss:0.21024\ttrain-f1score:0.72735\teval-logloss:0.28290\teval-f1score:0.65961\n",
      "[208]\ttrain-logloss:0.20829\ttrain-f1score:0.73048\teval-logloss:0.28302\teval-f1score:0.65985\n",
      "xgboost our out of folds CV f1score is 0.6291361629633896\n",
      "Epoch 1/50\n",
      "1058/1058 [==============================] - 3s 2ms/step - loss: 0.3633 - accuracy: 0.8732 - val_loss: 0.2834 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.3037 - accuracy: 0.8969 - val_loss: 0.2818 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2967 - accuracy: 0.8975 - val_loss: 0.2812 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2954 - accuracy: 0.8988 - val_loss: 0.2814 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2925 - accuracy: 0.8990 - val_loss: 0.2816 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2907 - accuracy: 0.8988 - val_loss: 0.2820 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2904 - accuracy: 0.8998 - val_loss: 0.2816 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2906 - accuracy: 0.8991 - val_loss: 0.2823 - val_accuracy: 0.9026 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2900 - accuracy: 0.8992 - val_loss: 0.2820 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2897 - accuracy: 0.8993 - val_loss: 0.2829 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2893 - accuracy: 0.8991 - val_loss: 0.2829 - val_accuracy: 0.9019 - lr: 9.0484e-04\n",
      "Epoch 12/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2882 - accuracy: 0.8993 - val_loss: 0.2826 - val_accuracy: 0.9023 - lr: 8.1873e-04\n",
      "Epoch 13/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2901 - accuracy: 0.8983 - val_loss: 0.2828 - val_accuracy: 0.9019 - lr: 7.4082e-04\n",
      "Epoch 14/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2896 - accuracy: 0.8980 - val_loss: 0.2814 - val_accuracy: 0.9024 - lr: 6.7032e-04\n",
      "Epoch 15/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2880 - accuracy: 0.8997 - val_loss: 0.2816 - val_accuracy: 0.9025 - lr: 6.0653e-04\n",
      "Epoch 16/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2872 - accuracy: 0.8991 - val_loss: 0.2818 - val_accuracy: 0.9023 - lr: 5.4881e-04\n",
      "Epoch 17/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2879 - accuracy: 0.8992 - val_loss: 0.2823 - val_accuracy: 0.9019 - lr: 4.9659e-04\n",
      "Epoch 18/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2877 - accuracy: 0.8990 - val_loss: 0.2822 - val_accuracy: 0.9020 - lr: 4.4933e-04\n",
      "Epoch 19/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2878 - accuracy: 0.9000 - val_loss: 0.2821 - val_accuracy: 0.9022 - lr: 4.0657e-04\n",
      "Epoch 20/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2872 - accuracy: 0.8994 - val_loss: 0.2815 - val_accuracy: 0.9024 - lr: 3.6788e-04\n",
      "Epoch 21/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2871 - accuracy: 0.9001 - val_loss: 0.2816 - val_accuracy: 0.9025 - lr: 3.3287e-04\n",
      "Epoch 22/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2869 - accuracy: 0.8998 - val_loss: 0.2817 - val_accuracy: 0.9024 - lr: 3.0119e-04\n",
      "Epoch 23/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2869 - accuracy: 0.8993 - val_loss: 0.2816 - val_accuracy: 0.9024 - lr: 2.7253e-04\n",
      "Epoch 24/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2863 - accuracy: 0.8990 - val_loss: 0.2816 - val_accuracy: 0.9019 - lr: 2.4660e-04\n",
      "Epoch 25/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2876 - accuracy: 0.8981 - val_loss: 0.2815 - val_accuracy: 0.9019 - lr: 2.2313e-04\n",
      "Epoch 26/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2879 - accuracy: 0.8992 - val_loss: 0.2816 - val_accuracy: 0.9019 - lr: 2.0190e-04\n",
      "Epoch 27/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2866 - accuracy: 0.9003 - val_loss: 0.2816 - val_accuracy: 0.9024 - lr: 1.8268e-04\n",
      "Epoch 28/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2873 - accuracy: 0.9003 - val_loss: 0.2818 - val_accuracy: 0.9023 - lr: 1.6530e-04\n",
      "Epoch 29/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2874 - accuracy: 0.8991 - val_loss: 0.2815 - val_accuracy: 0.9024 - lr: 1.4957e-04\n",
      "Epoch 30/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2869 - accuracy: 0.9000 - val_loss: 0.2815 - val_accuracy: 0.9020 - lr: 1.3534e-04\n",
      "Epoch 31/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2877 - accuracy: 0.8989 - val_loss: 0.2816 - val_accuracy: 0.9020 - lr: 1.2246e-04\n",
      "Epoch 32/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2864 - accuracy: 0.9000 - val_loss: 0.2814 - val_accuracy: 0.9023 - lr: 1.1080e-04\n",
      "Epoch 33/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2861 - accuracy: 0.9003 - val_loss: 0.2814 - val_accuracy: 0.9022 - lr: 1.0026e-04\n",
      "Epoch 34/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2859 - accuracy: 0.8997 - val_loss: 0.2813 - val_accuracy: 0.9024 - lr: 9.0718e-05\n",
      "Epoch 35/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2868 - accuracy: 0.9002 - val_loss: 0.2817 - val_accuracy: 0.9024 - lr: 8.2085e-05\n",
      "Epoch 36/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2861 - accuracy: 0.9001 - val_loss: 0.2815 - val_accuracy: 0.9024 - lr: 7.4274e-05\n",
      "Epoch 37/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2865 - accuracy: 0.8990 - val_loss: 0.2816 - val_accuracy: 0.9022 - lr: 6.7206e-05\n",
      "Epoch 38/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2873 - accuracy: 0.8995 - val_loss: 0.2814 - val_accuracy: 0.9023 - lr: 6.0810e-05\n",
      "Epoch 39/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2860 - accuracy: 0.9000 - val_loss: 0.2816 - val_accuracy: 0.9024 - lr: 5.5023e-05\n",
      "Epoch 40/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2862 - accuracy: 0.9002 - val_loss: 0.2814 - val_accuracy: 0.9022 - lr: 4.9787e-05\n",
      "Epoch 41/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2872 - accuracy: 0.8996 - val_loss: 0.2816 - val_accuracy: 0.9023 - lr: 4.5049e-05\n",
      "Epoch 42/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2868 - accuracy: 0.8997 - val_loss: 0.2814 - val_accuracy: 0.9023 - lr: 4.0762e-05\n",
      "Epoch 43/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2856 - accuracy: 0.9003 - val_loss: 0.2814 - val_accuracy: 0.9023 - lr: 3.6883e-05\n",
      "Epoch 44/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2884 - accuracy: 0.8992 - val_loss: 0.2815 - val_accuracy: 0.9024 - lr: 3.3373e-05\n",
      "Epoch 45/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2861 - accuracy: 0.9008 - val_loss: 0.2815 - val_accuracy: 0.9022 - lr: 3.0197e-05\n",
      "Epoch 46/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2862 - accuracy: 0.9007 - val_loss: 0.2816 - val_accuracy: 0.9020 - lr: 2.7324e-05\n",
      "Epoch 47/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2862 - accuracy: 0.9007 - val_loss: 0.2816 - val_accuracy: 0.9022 - lr: 2.4724e-05\n",
      "Epoch 48/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2871 - accuracy: 0.9002 - val_loss: 0.2817 - val_accuracy: 0.9020 - lr: 2.2371e-05\n",
      "Epoch 49/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2865 - accuracy: 0.9008 - val_loss: 0.2816 - val_accuracy: 0.9020 - lr: 2.0242e-05\n",
      "Epoch 50/50\n",
      "1058/1058 [==============================] - 2s 2ms/step - loss: 0.2870 - accuracy: 0.8995 - val_loss: 0.2814 - val_accuracy: 0.9020 - lr: 1.8316e-05\n"
     ]
    }
   ],
   "source": [
    "#学習の実行\n",
    "Learning_and_Predicting(train_df, test_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postprocessing\n",
    "\n",
    "def Postprocessing(train_df, test_df):\n",
    "    #最適な閾値を見つける関数\n",
    "    def find_best_threshold_and_score(y_true, y_pred_proba):\n",
    "        best_threshold = 0\n",
    "        best_score = 0\n",
    "        for threshold in np.linspace(0, 1, 1001):\n",
    "            score = f1_score(y_true, y_pred_proba >= threshold, average='macro')\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_threshold = threshold\n",
    "        return best_threshold, best_score\n",
    "    \n",
    "    # ニューラルネットワークモデルの学習データに対する予測確率\n",
    "    nn_model = load_model(f'nn_stacking_model_seed{CFG.seed}_ver{CFG.VER}.h5')\n",
    "    train_pred_proba_nn = nn_model.predict(train_df,oof_combined_features_scaled).flatten()\n",
    "    \n",
    "    # 最適な閾値とスコアを求める\n",
    "    best_threshold_nn, best_score_nn = find_best_threshold_and_score(train_df[CFG.target_col], train_pred_proba_nn)\n",
    "    print(f'NN Best Threshold: {best_threshold_nn}, Best F1 Score: {best_score_nn}')\n",
    "    \n",
    "    # テストデータに対する最終予測\n",
    "    test_pred_proba_nn = nn_model.predict(test_combined_features_scaled).flatten()\n",
    "    test_final_predictions_nn = (test_pred_proba_nn >= best_threshold_nn).astype(int)\n",
    "    # 最終予測結果をコンペ提出用のフォーマットでCSVファイルに出力\n",
    "    submission_df_nn = pd.DataFrame({'Id': test_df.index, 'target': test_final_predictions_nn}).reset_index(drop=True)\n",
    "    submission_df_nn['Id'] = submission_df_nn.index + 4230\n",
    "    submission_df_nn.to_csv(f'stacking_nn_submission_best_score{best_score_nn:.4f}_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}.csv', header=False, index=False)\n",
    "    \n",
    "    \n",
    "    # ロジスティック回帰モデルの学習データに対する予測確率\n",
    "    lr_model = pickle.load(open(f'lr_stacking_model_seed{CFG.seed}_ver{CFG.VER}.pkl','rb'))\n",
    "    train_pred_proba_lr = lr_model.predict_proba(oof_combined_features_scaled)[:, 1]\n",
    "    \n",
    "    # 最適な閾値とスコアを求める\n",
    "    best_threshold_lr, best_score_lr = find_best_threshold_and_score(train_df[CFG.target_col], train_pred_proba_nn)\n",
    "    print(f'LR Best Threshold: {best_threshold_lr}, Best F1 Score: {best_score_lr}')\n",
    "    \n",
    "    # テストデータに対する最終予測\n",
    "    test_pred_proba_lr = lr_model.predict_proba(test_combined_features_scaled)[:, 1]\n",
    "    test_final_predictions_lr = (test_pred_proba_lr >= best_threshold_lr).astype(int)\n",
    "    # 最終予測結果をコンペ提出用のフォーマットでCSVファイルに出力\n",
    "    submission_df_lr = pd.DataFrame({'Id': test_df.index, 'target': test_final_predictions_lr}).reset_index(drop=True)\n",
    "    submission_df_lr['Id'] = submission_df_lr.index + 4230\n",
    "    submission_df_lr.to_csv(f'stacking_lr_submission_best_score{best_score_lr:.4f}_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Postprocessing() takes 0 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15284/3766098792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#予測の実行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mPostprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Postprocessing() takes 0 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "#予測の実行\n",
    "Postprocessing(train_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13858cd0c554419bb867071b5c810b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4074a8c3b85548ed9424375a19416c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573ab758539147f1a2bc21ac9f0347ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5de7c5cebd814e1caa8437775031ea12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6762ef5aab7e4d18b98e7d837dedc03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f14799525cf44158bbffc0e9a08891b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7dceec9910a46cea90915015ca58358",
      "placeholder": "​",
      "style": "IPY_MODEL_573ab758539147f1a2bc21ac9f0347ce",
      "value": "100%"
     }
    },
    "76ddf1599bb144b2a6b4573027c6f662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4074a8c3b85548ed9424375a19416c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_13858cd0c554419bb867071b5c810b30",
      "value": " 1000/1000 [00:19&lt;00:00, 37.91it/s]"
     }
    },
    "b0ab4a4e03b242e2ae3610b6a52b5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7dceec9910a46cea90915015ca58358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d239d2ff297a4c00aa350f8699ca6bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de7c5cebd814e1caa8437775031ea12",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0ab4a4e03b242e2ae3610b6a52b5c14",
      "value": 1000
     }
    },
    "ef58b4abcf0f43cd90a523a3875a2f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f14799525cf44158bbffc0e9a08891b",
       "IPY_MODEL_d239d2ff297a4c00aa350f8699ca6bb1",
       "IPY_MODEL_76ddf1599bb144b2a6b4573027c6f662"
      ],
      "layout": "IPY_MODEL_6762ef5aab7e4d18b98e7d837dedc03f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
